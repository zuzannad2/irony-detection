{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from xml.dom import minidom\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import  accuracy_score\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import emoji\n",
    "from sklearn.utils import shuffle\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = [el.split('.')[0] for el in os.listdir('en')]\n",
    "labels = np.loadtxt('en/truth.txt', delimiter=':::', dtype=np.str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(authors, test_size=0.2, random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "336"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = shuffle(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(xml):\n",
    "    tweets = []\n",
    "    doc = minidom.parse(xml)\n",
    "    doclist = doc.getElementsByTagName('document')\n",
    "    for i in range(len(doclist)):\n",
    "        tweet = doclist[i].firstChild.nodeValue\n",
    "        tweets.append(tweet.rstrip('\\n'))\n",
    "\n",
    "    return np.array(tweets)\n",
    "\n",
    "def binarize_label(label):\n",
    "    if label == 'NI': return 0\n",
    "    elif label == 'I': return 1\n",
    "\n",
    "def compose_dataset(labels, authors):\n",
    "    dataset = {}\n",
    "    dataset_for_tokenizing = {}\n",
    "    labels_out = []\n",
    "    for label in labels:\n",
    "        id, cls = label[0], label[1]\n",
    "        if id in authors:\n",
    "            dataset[id] = ''\n",
    "            dataset_for_tokenizing[id] = []\n",
    "            tweets = parse(os.path.join('en/', id + '.xml'))\n",
    "            tweets = [emoji.demojize(tweet.replace('/n','')) for tweet in tweets]\n",
    "            for tweet in tweets:\n",
    "                dataset[id] += tweet\n",
    "                dataset_for_tokenizing[id].append(tweet)\n",
    "            labels_out.append(binarize_label(cls))\n",
    "    return dataset, dataset_for_tokenizing, labels_out\n",
    "\n",
    "train_ds, train_tokens, labels_train = compose_dataset(labels, train)\n",
    "#val_ds, val_tokens, labels_val = compose_dataset(labels, val)\n",
    "test_ds, test_tokens, labels_test = compose_dataset(labels, test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical features\n",
    "- Punctuation marks\n",
    "- Average tweet length\n",
    "- Emoticons \n",
    "- Capitalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_tweets(ds):\n",
    "    tk = TweetTokenizer()\n",
    "    dout = {}\n",
    "    for author in ds.keys():\n",
    "        dout[author] = []\n",
    "        for tweet in ds[author]:\n",
    "            dout[author].append(tk.tokenize(tweet))\n",
    "    return dout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_features(tokenized_ds):\n",
    "    dout = {}\n",
    "    for author in tokenized_ds.keys():\n",
    "        length = []\n",
    "        capitalisation_counts = []\n",
    "        punct_counts = []\n",
    "        emoji_counts = []\n",
    "        hashtags = []\n",
    "        links = []\n",
    "        user_mentions = []\n",
    "        for tweet in tokenized_ds[author]:\n",
    "            emojis = len(emoji.emoji_lis(emoji.emojize(''.join(tweet))))\n",
    "            emoji_counts.append(emojis)\n",
    "            length.append(len(tweet))\n",
    "            pc = 0\n",
    "            cc = 0\n",
    "            hs = 0\n",
    "            urls = 0\n",
    "            usrs = 0\n",
    "            for el in tweet:\n",
    "                if el in punctuation and el != '#':\n",
    "                    pc += 1\n",
    "                if el.isupper():\n",
    "                    cc += 1\n",
    "                if el == '#HASHTAG':\n",
    "                    hs += 1\n",
    "                if el == '#URL':\n",
    "                    urls += 1\n",
    "                if el == '#USER':\n",
    "                    usrs += 1\n",
    "            punct_counts.append(pc)\n",
    "            capitalisation_counts.append(cc)\n",
    "            hashtags.append(hs)\n",
    "            links.append(urls)\n",
    "            user_mentions.append(usrs)\n",
    "        dout[author] = [np.mean(length),\n",
    "                        np.mean(capitalisation_counts),\n",
    "                        np.mean(punct_counts),\n",
    "                        np.mean(emoji_counts),\n",
    "                        np.mean(hashtags),\n",
    "                        np.mean(links),\n",
    "                        np.mean(user_mentions)]\n",
    "    return dout\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_train = tokenize_tweets(train_tokens)\n",
    "#tokenized_val = tokenize_tweets(val_tokens)\n",
    "tokenized_test = tokenize_tweets(test_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:12: DeprecationWarning: 'emoji.emoji_lis()' is deprecated and will be removed in version 2.0.0. Use method emoji.emoji_list(str) instead.\n",
      "To hide this warning, pin/downgrade the package to 'emoji~=1.6.3'\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "features_train = produce_features(tokenized_train)\n",
    "#features_val = produce_features(tokenized_val)\n",
    "features_test = produce_features(tokenized_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xstat = np.array(list(features_train.values()))\n",
    "#Xvalstat = np.array(list(features_val.values()))\n",
    "Xteststat = np.array(list(features_test.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "cv = CountVectorizer(analyzer = 'word', ngram_range=(1,3), stop_words='english')\n",
    "cv_char = CountVectorizer(analyzer = 'char', ngram_range=(1,3), stop_words='english')\n",
    "\n",
    "bow = cv.fit_transform(train_ds.values())\n",
    "bow_char = cv_char.fit_transform(train_ds.values())\n",
    "Xword = bow\n",
    "Xchar = bow_char\n",
    "\n",
    "# bow = cv.transform(val_ds.values())\n",
    "# bow_char = cv_char.transform(val_ds.values())\n",
    "# Xvalword = bow\n",
    "# Xvalchar = bow_char\n",
    "\n",
    "bow = cv.transform(test_ds.values())\n",
    "bow_char = cv_char.transform(test_ds.values())\n",
    "Xtestword = bow\n",
    "Xtestchar = bow_char"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "    DecisionTreeClassifier(max_depth=50),\n",
    "    RandomForestClassifier(max_depth=50, n_estimators=100, max_features=1),\n",
    "    AdaBoostClassifier(),\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(),\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\n",
    "    \"Nearest Neighbors\",\n",
    "    \"Linear SVM\",\n",
    "    \"RBF SVM\",\n",
    "    \"Decision Tree\",\n",
    "    \"Random Forest\",\n",
    "    \"AdaBoost\",\n",
    "    \"Multinomial Naive Bayes\",\n",
    "    \"Logistic Regression\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the best classifier for the statistical feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier:  Nearest Neighbors\n",
      "CV score:  0.7614035087719299\n",
      "Classifier:  Linear SVM\n",
      "CV score:  0.7349122807017543\n",
      "Classifier:  RBF SVM\n",
      "CV score:  0.7103157894736842\n",
      "Classifier:  Decision Tree\n",
      "CV score:  0.8171929824561402\n",
      "Classifier:  Random Forest\n",
      "CV score:  0.8781052631578946\n",
      "Classifier:  AdaBoost\n",
      "CV score:  0.8755438596491227\n",
      "Classifier:  Multinomial Naive Bayes\n",
      "CV score:  0.634280701754386\n",
      "Classifier:  Logistic Regression\n",
      "CV score:  0.7932280701754385\n"
     ]
    }
   ],
   "source": [
    "for classifier, name in zip(classifiers, names):\n",
    "    print('Classifier: ', name)\n",
    "    classifier.fit(Xstat, labels_train)\n",
    "    scores = cross_val_score(classifier, Xstat, labels_train, cv=5)\n",
    "    print('CV score: ', scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the best classifier for the word level n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier:  Nearest Neighbors\n",
      "Accuracy score:  0.8111929824561404\n",
      "Classifier:  Linear SVM\n",
      "Accuracy score:  0.8965263157894737\n",
      "Classifier:  RBF SVM\n",
      "Accuracy score:  0.5198947368421053\n",
      "Classifier:  Decision Tree\n",
      "Accuracy score:  0.8066315789473684\n",
      "Classifier:  Random Forest\n",
      "Accuracy score:  0.5516140350877192\n",
      "Classifier:  AdaBoost\n",
      "Accuracy score:  0.8993684210526316\n",
      "Classifier:  Multinomial Naive Bayes\n",
      "Accuracy score:  0.8697894736842106\n",
      "Classifier:  Logistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.893859649122807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "for classifier, name in zip(classifiers, names):\n",
    "    print('Classifier: ', name)\n",
    "    classifier.fit(Xword, labels_train)\n",
    "    y_pred = classifier.predict(Xtestword)\n",
    "    scores = cross_val_score(classifier, Xword, labels_train, cv=5)\n",
    "    print('Accuracy score: ', scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the best classifier for the character level n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier:  Nearest Neighbors\n",
      "Accuracy score:  0.8171578947368421\n",
      "Classifier:  Linear SVM\n",
      "Accuracy score:  0.8859298245614035\n",
      "Classifier:  RBF SVM\n",
      "Accuracy score:  0.5198947368421053\n",
      "Classifier:  Decision Tree\n",
      "Accuracy score:  0.8012280701754385\n",
      "Classifier:  Random Forest\n",
      "Accuracy score:  0.8196140350877194\n",
      "Classifier:  AdaBoost\n",
      "Accuracy score:  0.907298245614035\n",
      "Classifier:  Multinomial Naive Bayes\n",
      "Accuracy score:  0.8409473684210527\n",
      "Classifier:  Logistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.8673684210526316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "for classifier, name in zip(classifiers, names):\n",
    "    print('Classifier: ', name)\n",
    "    classifier.fit(Xchar, labels_train)\n",
    "    y_pred = classifier.predict(Xtestchar)\n",
    "    scores = cross_val_score(classifier, Xchar, labels_train, cv=5)\n",
    "    print('Accuracy score: ', scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search for hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_svm = {'C': [0.1, 1, 10, 100, 1000],\n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "              'kernel': ['rbf','linear']}\n",
    "\n",
    "grid_adaboost = {}\n",
    "grid_adaboost['n_estimators'] = [10, 50, 100, 500]\n",
    "grid_adaboost['learning_rate'] = [0.0001, 0.001, 0.01, 0.1, 1.0]\n",
    "\n",
    "grid_rf = {'max_depth': range(10,150,10), 'n_estimators':range(10,150,10), 'max_features':range(1,5)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.936526 using {'learning_rate': 0.1, 'n_estimators': 500}\n"
     ]
    }
   ],
   "source": [
    "ab = AdaBoostClassifier(learning_rate=0.1,n_estimators=500)\n",
    "grid_search = GridSearchCV(estimator=ab, param_grid=grid_adaboost, n_jobs=-1, cv=5, scoring='accuracy')\n",
    "\n",
    "# execute the grid search\n",
    "grid_result = grid_search.fit(Xchar, labels_train)\n",
    "\n",
    "# summarize the best score and configuration\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.902070 using {'max_depth': 10, 'max_features': 3, 'n_estimators': 40}\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=grid_rf, n_jobs=-1, cv=5, scoring='accuracy')\n",
    "\n",
    "# execute the grid search\n",
    "grid_result = grid_search.fit(Xstat, labels_train)\n",
    "\n",
    "# summarize the best score and configuration\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.896526 using {'C': 0.1, 'gamma': 1, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "svm = SVC()\n",
    "grid_search = GridSearchCV(estimator=svm, param_grid=grid_svm, n_jobs=-1, cv=5, scoring='accuracy')\n",
    "\n",
    "# execute the grid search\n",
    "grid_result = grid_search.fit(Xword, labels_train)\n",
    "\n",
    "# summarize the best score and configuration\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear SVM\n",
    "svm = SVC(kernel=\"linear\", C=0.1, gamma=1)\n",
    "svm.fit(Xword, labels_train)\n",
    "y_pred_svm = svm.predict(Xtestword)\n",
    "\n",
    "# AdaBoost\n",
    "dt = AdaBoostClassifier(learning_rate=0.1,n_estimators=500)\n",
    "dt.fit(Xchar, labels_train)\n",
    "y_pred_dt = dt.predict(Xtestchar)\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier(max_depth=10, n_estimators=40, max_features=3)\n",
    "rf.fit(Xstat, labels_train)\n",
    "y_pred_rf = rf.predict(Xteststat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Majority Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "summed_preds = y_pred_svm + y_pred_dt + y_pred_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_total = [0 if el < 2 else 1 for el in summed_preds ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Before the GridSearch\n",
    "Accuracy score : 0.9302\n",
    "#### After, with test set = 0.1\n",
    "Accuracy score : 0.9767\n",
    "#### After, with test set = 0.2\n",
    "Accuracy score : 0.9647\n",
    "#### After, with test set = 0.3\n",
    "Accuracy score : 0.9528\n",
    "#### After, with test set = 0.4\n",
    "Accuracy score : 0.9408"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score : 0.9765\n"
     ]
    }
   ],
   "source": [
    "score = accuracy_score(labels_test, y_pred_total)\n",
    "print('Accuracy score : {}'.format(np.round(score,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9176470588235294\n",
      "0.9647058823529412\n",
      "0.8705882352941177\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(labels_test,y_pred_svm))\n",
    "print(accuracy_score(labels_test,y_pred_dt))\n",
    "print(accuracy_score(labels_test,y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
